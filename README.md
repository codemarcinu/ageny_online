# ðŸš€ Ageny Online

**Online AI Agents API** - PrzeksztaÅ‚cenie aplikacji FoodSave AI z lokalnych modeli Ollama na wersjÄ™ online wykorzystujÄ…cÄ… zewnÄ™trzne API modeli jÄ™zykowych.

## ðŸ“‹ Opis Projektu

Ageny Online to nowoczesna platforma AI, ktÃ³ra eliminuje zaleÅ¼noÅ›Ä‡ od lokalnych modeli jÄ™zykowych i GPU, umoÅ¼liwiajÄ…c uruchomienie na dowolnym laptopie z dostÄ™pem do internetu.

### ðŸŽ¯ GÅ‚Ã³wne Zalety

- âœ… **Brak wymagaÅ„ GPU** - dziaÅ‚a na kaÅ¼dym laptopie
- âœ… **Niskie koszty infrastruktury** - tylko koszty API
- âœ… **Wysoka dostÄ™pnoÅ›Ä‡** - skalowalne rozwiÄ…zanie
- âœ… **ÅatwoÅ›Ä‡ wdroÅ¼enia** - minimalna konfiguracja
- âœ… **Automatyczny fallback** - redundancja dostawcÃ³w

## ðŸ—ï¸ Architektura

### Komponenty AI

| Komponent | Dostawcy | Koszt |
|-----------|----------|-------|
| **Chat Model** | OpenAI GPT-4, Mistral AI | $0.01-0.03/1K tokens |
| **Embedding** | OpenAI, Mistral | $0.00002/1K tokens |
| **Vector Store** | Pinecone, Weaviate | $0.10/1K operations |
| **OCR** | Azure Vision, Google Vision | $1.50/1K transactions |

### Struktura Projektu

```
ageny_online/
â”œâ”€â”€ src/backend/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ llm_providers/         # OpenAI, Mistral
â”‚   â”‚   â”œâ”€â”€ ocr_providers/         # Azure Vision, Google Vision
â”‚   â”‚   â””â”€â”€ vector_stores/         # Pinecone, Weaviate
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ v2/endpoints/          # REST API endpoints
â”‚   â”‚   â””â”€â”€ main.py                # FastAPI app
â”‚   â””â”€â”€ config.py                  # Konfiguracja
â”œâ”€â”€ requirements.txt               # ZaleÅ¼noÅ›ci Python
â”œâ”€â”€ env.example                    # PrzykÅ‚ad konfiguracji
â””â”€â”€ README.md                      # Dokumentacja
```

## ðŸš€ Szybki Start

### 1. Instalacja

```bash
# Klonowanie repozytorium
git clone https://github.com/codemarcinu/ageny_online.git
cd ageny_online

# Tworzenie Å›rodowiska wirtualnego
python -m venv venv
source venv/bin/activate  # Linux/Mac
# lub
venv\Scripts\activate     # Windows

# Instalacja zaleÅ¼noÅ›ci
pip install -r requirements.txt
```

### 2. Konfiguracja

```bash
# Kopiowanie pliku konfiguracyjnego
cp env.example .env.online

# Edycja konfiguracji
nano .env.online
```

**Minimalna konfiguracja:**
```env
# OpenAI (wymagane)
OPENAI_API_KEY=your_openai_api_key_here

# Mistral (opcjonalne)
MISTRAL_API_KEY=your_mistral_api_key_here

# Azure Vision (opcjonalne)
AZURE_VISION_KEY=your_azure_vision_key_here
AZURE_VISION_ENDPOINT=https://your-resource.cognitiveservices.azure.com/

# Pinecone (opcjonalne)
PINECONE_API_KEY=your_pinecone_api_key_here
```

### 3. Uruchomienie

```bash
# Uruchomienie serwera
python -m src.backend.api.main

# Lub z uvicorn
uvicorn src.backend.api.main:app --host 0.0.0.0 --port 8000 --reload
```

### 4. DostÄ™p do API

- **API Documentation**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health
- **Providers Status**: http://localhost:8000/api/v1/providers

## ðŸ“š API Endpoints

### Chat Completions

```bash
# Pojedyncze zapytanie
curl -X POST "http://localhost:8000/api/v2/chat/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "Hello, how are you?"}
    ],
    "model": "gpt-4o-mini"
  }'

# Batch processing
curl -X POST "http://localhost:8000/api/v2/chat/batch" \
  -H "Content-Type: application/json" \
  -d '[
    {
      "messages": [{"role": "user", "content": "Hello"}],
      "model": "gpt-4o-mini"
    }
  ]'
```

### OCR Processing

```bash
# Upload image for OCR
curl -X POST "http://localhost:8000/api/v2/ocr/extract" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@receipt.jpg"
```

### Vector Store Operations

```bash
# Create index
curl -X POST "http://localhost:8000/api/v2/vector-store/index/create" \
  -H "Content-Type: application/json" \
  -d '{
    "provider": "pinecone",
    "index_name": "documents",
    "dimension": 1536
  }'

# Upload documents
curl -X POST "http://localhost:8000/api/v2/vector-store/documents/upload" \
  -H "Content-Type: application/json" \
  -d '{
    "documents": [
      {
        "id": "doc1",
        "text": "Sample document text",
        "metadata": {"category": "sample"}
      }
    ],
    "index_name": "documents",
    "provider": "pinecone"
  }'

# Search documents
curl -X POST "http://localhost:8000/api/v2/vector-store/search" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "sample document",
    "index_name": "documents",
    "top_k": 5
  }'
```

## ðŸ’° Koszty

### PrzykÅ‚adowe Koszty (dzienne)

| Operacja | IloÅ›Ä‡ | Koszt |
|----------|-------|-------|
| Chat completions | 1000 zapytaÅ„ | $0.50-1.50 |
| Embeddings | 10,000 tekstÃ³w | $0.20 |
| OCR | 100 obrazÃ³w | $0.15 |
| Vector operations | 10,000 operacji | $1.00 |

**ÅÄ…czny koszt dzienny: ~$2-3 USD**

### Optymalizacja KosztÃ³w

1. **UÅ¼ywaj taÅ„szych modeli** (gpt-4o-mini zamiast gpt-4o)
2. **Batch processing** dla wiÄ™kszej iloÅ›ci danych
3. **Caching** dla powtarzajÄ…cych siÄ™ zapytaÅ„
4. **Monitoring** kosztÃ³w przez `/api/v1/costs`

## ðŸ”§ Konfiguracja DostawcÃ³w

### Wymagania dla DostawcÃ³w

KaÅ¼dy dostawca ma okreÅ›lone wymagania konfiguracyjne. System automatycznie sprawdza dostÄ™pnoÅ›Ä‡ dostawcÃ³w na podstawie ustawionych zmiennych Å›rodowiskowych.

#### OpenAI (LLM)
**Wymagane**: `OPENAI_API_KEY`
```env
OPENAI_API_KEY=sk-...
OPENAI_ORGANIZATION=org-...  # opcjonalne
OPENAI_MODEL=gpt-4o-mini     # domyÅ›lnie
```

#### Mistral AI (LLM)
**Wymagane**: `MISTRAL_API_KEY`
```env
MISTRAL_API_KEY=your_mistral_key
MISTRAL_MODEL=mistral-small-latest  # domyÅ›lnie
```

#### Azure Vision (OCR)
**Wymagane**: `AZURE_VISION_KEY` + `AZURE_VISION_ENDPOINT`
```env
AZURE_VISION_KEY=your_azure_key
AZURE_VISION_ENDPOINT=https://your-resource.cognitiveservices.azure.com/
AZURE_VISION_REGION=westeurope  # opcjonalne
```

#### Google Vision (OCR)
**Wymagane**: `GOOGLE_VISION_PROJECT_ID` + `GOOGLE_VISION_CREDENTIALS_PATH`
```env
GOOGLE_VISION_PROJECT_ID=your-project-id
GOOGLE_VISION_CREDENTIALS_PATH=/path/to/service-account.json
```

#### Pinecone (Vector Store)
**Wymagane**: `PINECONE_API_KEY`
```env
PINECONE_API_KEY=your_pinecone_key
PINECONE_ENVIRONMENT=gcp-starter  # domyÅ›lnie
```

#### Weaviate (Vector Store)
**Wymagane**: `WEAVIATE_URL`
```env
WEAVIATE_URL=https://your-weaviate-instance.network
WEAVIATE_API_KEY=your_api_key  # opcjonalne
WEAVIATE_USERNAME=your_username  # opcjonalne
WEAVIATE_PASSWORD=your_password  # opcjonalne
```

### Sprawdzanie Statusu DostawcÃ³w

```bash
# Sprawdzenie dostÄ™pnych dostawcÃ³w
curl http://localhost:8000/api/v1/providers

# PrzykÅ‚adowa odpowiedÅº:
{
  "openai": true,
  "mistral": false,
  "azure_vision": true,
  "google_vision": false,
  "pinecone": true,
  "weaviate": false
}
```

### Priorytety DostawcÃ³w

System automatycznie wybiera dostÄ™pnych dostawcÃ³w wedÅ‚ug priorytetÃ³w:

```env
# Priorytety LLM (od najwyÅ¼szego)
LLM_PROVIDER_PRIORITY=openai,mistral

# Priorytety OCR
OCR_PROVIDER_PRIORITY=azure_vision,google_vision

# Priorytety Vector Store
VECTOR_STORE_PRIORITY=pinecone,weaviate
```

### OpenAI

1. Zarejestruj siÄ™ na [OpenAI Platform](https://platform.openai.com/)
2. Wygeneruj API key
3. Dodaj do `.env.online`:
```env
OPENAI_API_KEY=sk-...
OPENAI_ORGANIZATION=org-...  # opcjonalne
```

## ðŸ§ª Testowanie

### Uruchamianie TestÃ³w

```bash
# PrzejdÅº do katalogu ageny_online
cd ageny_online

# Uruchomienie wszystkich testÃ³w jednostkowych
pytest tests/unit/

# Uruchomienie testÃ³w z pokazaniem postÄ™pu
pytest tests/unit/ -v

# Testy z coverage
pytest --cov=src tests/unit/

# Testy integracyjne
pytest tests/integration/

# Uruchomienie konkretnego testu
pytest tests/unit/test_config.py::TestSettings::test_settings_default_values -v
```

### Wymagania do TestÃ³w

- **Python 3.12+**
- **Virtual environment** z zainstalowanymi zaleÅ¼noÅ›ciami
- **Plik .env.online** (moÅ¼na uÅ¼yÄ‡ `env.example` jako szablonu)

### Mockowanie i Izolacja

Wszystkie testy sÄ… **w peÅ‚ni izolowane** i nie wymagajÄ… prawdziwych kluczy API:

- âœ… **LLM Providers**: Mockowane OpenAI i Mistral API
- âœ… **OCR Providers**: Mockowane Azure Vision i Google Vision
- âœ… **Vector Stores**: Mockowane Pinecone i Weaviate
- âœ… **Konfiguracja**: KaÅ¼dy test ma wÅ‚asnÄ… instancjÄ™ Settings
- âœ… **Brak poÅ‚Ä…czeÅ„ sieciowych**: Testy dziaÅ‚ajÄ… offline

### Struktura TestÃ³w

```
tests/
â”œâ”€â”€ unit/                    # Testy jednostkowe
â”‚   â”œâ”€â”€ test_config.py      # Testy konfiguracji
â”‚   â”œâ”€â”€ test_llm_providers.py    # Testy OpenAI/Mistral
â”‚   â”œâ”€â”€ test_ocr_providers.py    # Testy Azure/Google Vision
â”‚   â””â”€â”€ test_vector_stores.py    # Testy Pinecone/Weaviate
â”œâ”€â”€ integration/            # Testy integracyjne
â”‚   â””â”€â”€ test_api_endpoints.py    # Testy endpointÃ³w API
â””â”€â”€ conftest.py            # Konfiguracja pytest
```

### PrzykÅ‚ad Testu

```python
def test_openai_provider_initialization():
    """Test OpenAI provider initialization."""
    provider = OpenAIProvider("test-api-key")
    assert provider.default_model == "gpt-4o-mini"
    assert "gpt-4o-mini" in provider.models
```

### Status TestÃ³w

- **Testy jednostkowe**: 92/92 przechodzÄ… âœ…
- **Testy integracyjne**: Wszystkie przechodzÄ… âœ…
- **Coverage**: >95% pokrycia kodu

## ðŸ“Š Monitoring

### Metryki Prometheus

- **Endpoint**: http://localhost:8000/metrics
- **Dashboard**: Grafana (opcjonalnie)

### Health Checks

```bash
# Sprawdzenie statusu
curl http://localhost:8000/health

# Status dostawcÃ³w
curl http://localhost:8000/api/v1/providers
```

## ðŸš€ Deployment

### Docker

```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY src/ ./src/
COPY .env.online .

EXPOSE 8000
CMD ["uvicorn", "src.backend.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Docker Compose

```yaml
version: '3.8'
services:
  ageny-online:
    build: .
    ports:
      - "8000:8000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    volumes:
      - ./uploads:/app/uploads
```

## ðŸ¤ Contributing

### Przygotowanie Åšrodowiska

1. Fork the repository
2. Clone your fork:
   ```bash
   git clone https://github.com/your-username/ageny_online.git
   cd ageny_online
   ```
3. Create virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # lub venv\Scripts\activate  # Windows
   ```
4. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
5. Copy environment file:
   ```bash
   cp env.example .env.online
   ```

### Pisanie TestÃ³w

#### Best Practices

1. **UÅ¼ywaj wÅ‚asnej instancji Settings**:
   ```python
   def test_provider_availability(monkeypatch):
       class TestSettings(Settings):
           class Config:
               env_file = None
       
       monkeypatch.setenv("OPENAI_API_KEY", "test-key")
       test_settings = TestSettings()
       assert is_provider_available("openai", settings=test_settings) == True
   ```

2. **Mockuj zewnÄ™trzne API**:
   ```python
   with patch('backend.core.llm_providers.openai_client.AsyncOpenAI') as mock_client:
       mock_client.return_value.chat.completions.create = AsyncMock(return_value=mock_response)
       # test code...
   ```

3. **UÅ¼ywaj fixtures** dla wspÃ³lnych danych:
   ```python
   @pytest.fixture
   def sample_messages():
       return [{"role": "user", "content": "Hello"}]
   ```

4. **Testuj asynchroniczne funkcje**:
   ```python
   @pytest.mark.asyncio
   async def test_async_function():
       result = await some_async_function()
       assert result == expected_value
   ```

#### Struktura Testu

```python
class TestMyFeature:
    """Test cases for MyFeature."""
    
    def test_feature_initialization(self):
        """Test feature initialization."""
        feature = MyFeature("test-param")
        assert feature.param == "test-param"
    
    @pytest.mark.asyncio
    async def test_feature_async_operation(self):
        """Test async operation."""
        feature = MyFeature("test-param")
        result = await feature.async_operation()
        assert result["status"] == "success"
```

### Workflow Development

1. Create feature branch:
   ```bash
   git checkout -b feature/amazing-feature
   ```

2. Make changes and write tests:
   ```bash
   # Edytuj kod
   nano src/backend/core/my_feature.py
   
   # Napisz testy
   nano tests/unit/test_my_feature.py
   
   # Uruchom testy
   pytest tests/unit/test_my_feature.py -v
   ```

3. Ensure all tests pass:
   ```bash
   pytest tests/unit/ --tb=short
   ```

4. Commit changes:
   ```bash
   git add .
   git commit -m 'feat: add amazing feature with tests'
   ```

5. Push to branch:
   ```bash
   git push origin feature/amazing-feature
   ```

6. Open Pull Request

### Code Style

- **Python**: PEP 8, black formatter
- **Type hints**: Wymagane dla wszystkich funkcji publicznych
- **Docstrings**: Google style dla wszystkich klas i metod
- **Tests**: pytest, >90% coverage wymagane

### Commit Messages

UÅ¼ywaj conventional commits:
- `feat:` - nowa funkcjonalnoÅ›Ä‡
- `fix:` - naprawa bÅ‚Ä™du
- `docs:` - zmiany w dokumentacji
- `test:` - dodanie lub zmiana testÃ³w
- `refactor:` - refaktoryzacja kodu
- `chore:` - zadania konserwacyjne

## ðŸ“„ Licencja

Ten projekt jest licencjonowany pod MIT License - zobacz [LICENSE](LICENSE) dla szczegÃ³Å‚Ã³w.

## ðŸ†˜ Support

- **Issues**: [GitHub Issues](https://github.com/codemarcinu/ageny_online/issues)
- **Documentation**: [API Docs](http://localhost:8000/docs)
- **Email**: support@ageny-online.com

## ðŸ”„ Migracja z FoodSave AI

### Kroki Migracji

1. **Backup danych** z lokalnej bazy
2. **Eksport dokumentÃ³w** do formatu JSON
3. **Konfiguracja** nowych dostawcÃ³w API
4. **Import danych** do vector store
5. **Testowanie** funkcjonalnoÅ›ci
6. **WdroÅ¼enie** produkcyjne

### RÃ³Å¼nice Architektoniczne

| Aspekt | FoodSave AI (Lokalny) | Ageny Online |
|--------|----------------------|--------------|
| **GPU** | Wymagane (8GB+ VRAM) | Nie wymagane |
| **RAM** | 16GB+ | 4GB+ |
| **Koszty** | Energia + Infrastruktura | API calls |
| **SkalowalnoÅ›Ä‡** | Ograniczona | Nieograniczona |
| **DostÄ™pnoÅ›Ä‡** | Lokalna | Globalna |

---

**Ageny Online** - Nowoczesne AI bez GPU! ðŸš€ 